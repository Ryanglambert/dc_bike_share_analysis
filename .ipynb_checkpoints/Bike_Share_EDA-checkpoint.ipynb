{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, Ridge, LinearRegression, Lasso, Lars\n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fields\n",
    "\n",
    "- **datetime** - hourly date + timestamp  \n",
    "- **season** -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "- **holiday** - whether the day is considered a holiday\n",
    "- **workingday** - whether the day is neither a weekend nor holiday\n",
    "- **weather** \n",
    "\n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "\n",
    "\n",
    "- **temp** - temperature in Celsius\n",
    "- **atemp** - \"feels like\" temperature in Celsius\n",
    "- **humidity** - relative humidity\n",
    "- **windspeed** - wind speed\n",
    "- **casual** - number of non-registered user rentals initiated\n",
    "- **registered** - number of registered user rentals initiated\n",
    "- **count** - number of total rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Clean and Dummy-ize our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "hold_out = pd.read_csv('data/test.csv')\n",
    "\n",
    "def clean_frame(df, test_data=False):\n",
    "    seasons = {'spring':1, 'summer':2, 'winter':3, 'fall':4}\n",
    "    for season in seasons.iterkeys():\n",
    "        df[season] = df['season'].isin([seasons[season]])\n",
    "\n",
    "    weather_types = {'clear':1, 'mist':2, 'light':3, 'heavy':4}\n",
    "    for weather in weather_types:\n",
    "        df[weather] = df['weather'].isin([weather_types[weather]])\n",
    "\n",
    "    ### drop stuff we don't need ###\n",
    "    df = df.drop(['season', 'weather'], axis=1)\n",
    "    df = df.set_index('datetime')\n",
    "\n",
    "    ### Rearrange columns\n",
    "    if not test_data:\n",
    "        cols = df.columns\n",
    "        cols = cols[6:9].append(cols[:6]).append(cols[9:])\n",
    "        df = df[cols]\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "train = clean_frame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Weather, humidity, temperature are collinear with the seasons, so any time series analysis would need to account for this effect. \n",
    "\n",
    "I suspect that weather's effect on whether people will use a bike are somewhat transient.  70 degrees feels like a great day for a bike ride, but if it's been 40 degrees for weeks, a 55 degree day may also feel similar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairplot(train, pair_variables, y_var):\n",
    "    g = sns.pairplot(train[pair_variables],\n",
    "                 kind='reg',\n",
    "                 x_vars=pair_variables,\n",
    "                y_vars=y_var,\n",
    "                size=5)\n",
    "    g.set(ylim=(0, 1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations: Which Variables effect the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count against weather stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 'count'\n",
    "pairplot(train, [y, 'temp', 'humidity', 'windspeed'], y_var=[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count against Weather Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 'count'\n",
    "pairplot(train, [y, 'heavy', 'light', 'clear', 'mist'], y_var=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 'count'\n",
    "pairplot(train, [y, 'spring', 'fall', 'winter', 'summer'], y_var=[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations: Through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's look at how bike usage varies with time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_wk_day = train[train['workingday'] == 1]\n",
    "train_wknd = train[train['workingday'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_hours = train_wk_day.groupby(train_wk_day.index.hour)[['count', 'registered', 'casual']].mean()\n",
    "var = train_wk_day.groupby(train_wk_day.index.hour)['count'].var()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(train_hours.drop(['registered', 'casual'], axis=1))\n",
    "\n",
    "ax.fill_between(train_hours.index, train_hours['count'] - var,\n",
    "                 train_hours['count'] + var, alpha=0.1, \n",
    "                                                    color=\"r\")\n",
    "\n",
    "plt.xticks(range(0, 24, 1))\n",
    "# plt.ylim(0, 800)\n",
    "plt.title('Weekday +/- Variance')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "### Second Plot\n",
    "train_wknd_hours = train_wknd.groupby(train_wknd.index.hour)[['count','registered','casual']].mean()\n",
    "std_wknd = train_wknd.groupby(train_wknd.index.hour)['count'].var()\n",
    "\n",
    "# train_wknd_hours.plot(xticks=range(0,23,1), ylim=(0, 600))\n",
    "ax1 = fig.add_subplot(2, 1, 2)\n",
    "ax1.plot(train_wknd_hours.drop(['registered', 'casual'], axis=1))\n",
    "ax1.fill_between(train_wknd_hours.index, train_wknd_hours['count'] - std_wknd,\n",
    "                 train_wknd_hours['count'] + std_wknd, alpha=0.1, \n",
    "                                                    color=\"b\")\n",
    "\n",
    "\n",
    "plt.xticks(range(0, 24, 1))\n",
    "# plt.ylim(0,800)\n",
    "fig.tight_layout()\n",
    "plt.xlabel('Time of Day 24H')\n",
    "plt.title('Weekend +/- Variance')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('/Users/ryanlambert/Desktop/bikes_per_hour.png')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance is HUGE.  Going to see if segmenting this model down further helps at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Month of Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_wk_of_yr = train_wk_day.groupby(train_wk_day.index.month)[['count', 'registered', 'casual']].mean()\n",
    "var = train_wk_day.groupby(train_wk_day.index.month)['count'].var()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_wk_of_yr.drop(['registered', 'casual'], axis=1))\n",
    "\n",
    "ax.fill_between(train_wk_of_yr.index, train_wk_of_yr['count'] - var,\n",
    "                 train_wk_of_yr['count'] + var, alpha=0.1, \n",
    "                                                    color=\"r\")\n",
    "\n",
    "# plt.xticks(range(0, 24, 1))\n",
    "# plt.ylim(0, 800)\n",
    "plt.title('Month of year +/- Variance')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Month')\n",
    "\n",
    "plt.savefig('/Users/ryanlambert/Desktop/bikes_by_month.png')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what I have seen thus far I'm going to include hour of day as a dummy variable.  \n",
    "\n",
    "There is a clear signal that is a function of what time of day it is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_month_dummies(train_hrs):\n",
    "    month_dummies = pd.get_dummies(train_hrs.index.month).set_index(train_hrs.index)\n",
    "    data6 = train_hrs.join(month_dummies.set_index(train_hrs.index))\n",
    "    return data6\n",
    "\n",
    "def add_dummy_hours(train):\n",
    "    train_hrs = train.join(pd.get_dummies(train.index.hour, prefix='hr').set_index(train.index))\n",
    "    train_hrs.index = pd.to_datetime(train_hrs.index)\n",
    "    return train_hrs\n",
    "\n",
    "def resid_plot(y_pred, y_actual, title):\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(y_pred, y_pred - y_actual)\n",
    "    plt.title(title + \" Residuals\", fontsize=10)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.hist(y_pred - y_actual, orientation='horizontal')\n",
    "    plt.title(title + \" Hist of Residuals\", fontsize=10)\n",
    "    plt.savefig('/Users/ryanlambert/Desktop/' + title + \"_Hist_of_Residuals.png\")\n",
    "    plt.show()\n",
    "    plt.hexbin(y_pred, y_pred - y_actual, gridsize=20)\n",
    "    plt.title(title + \" Hexbin of Residuals\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Binomial Because I'm modeling counts but the variance is not equal to the mean so not Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "data = add_month_dummies(add_dummy_hours(clean_frame(train)))\n",
    "data[['spring', 'fall', 'winter', 'summer', 'heavy', 'light', 'clear', 'mist']] = data[['spring', 'fall', 'winter', 'summer', 'heavy', 'light', 'clear', 'mist']].astype(int)\n",
    "X_n_binom = data.drop(['casual', 'registered', 'count'], axis=1)\n",
    "y_n_binom = data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "neg_bin = sm.GLM(y_n_binom, \n",
    "                 X_n_binom.values, \n",
    "                 family=sm.genmod.families.family.NegativeBinomial(link=sm.genmod.families.links.log,\n",
    "                                                                   alpha=2.7))\n",
    "neg_bin_results = neg_bin.fit()\n",
    "neg_bin_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = neg_bin_results.predict(X_n_binom)\n",
    "\n",
    "resid_plot(y_pred, y_n_binom, 'Neg_binom')\n",
    "plt.savefig('/Users/ryanlambert/Desktop/neg_binom_resids.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val_neg_binom(y, X, alpha=2.7):\n",
    "    iterator = KFold(len(X), n_folds=2, shuffle=True)\n",
    "    scores = []\n",
    "    for train, test in iterator:\n",
    "        y_tr = y[train]\n",
    "        X_tr = X.values[train, :]\n",
    "        y_test = y[test]\n",
    "        X_test = X.values[test, :]\n",
    "        model = sm.GLM(y_tr,\n",
    "                    X_tr,\n",
    "                    family=sm.genmod.families.family.NegativeBinomial(link=sm.genmod.families.links.log,\n",
    "                                                                       alpha=alpha))\n",
    "        model_results = model.fit()\n",
    "        y_pred_cross = model_results.predict(poly.fit_transform(X_test))\n",
    "        scores.append(mean_squared_error(y_test, y_pred_cross))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_sm(y_n_binom, X_n_binom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alphas = [np.linspace(2.5, 2.7, 5)]\n",
    "# alpha_scores = []\n",
    "# for alpha in alphas:\n",
    "#     scores = cross_val_sm(y_n_binom, X_n_binom, alpha=alpha)\n",
    "#     alpha_scores.append((alpha, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "neg_bin_interact = sm.GLM(y_n_binom, \n",
    "                 poly.fit_transform(X_n_binom), \n",
    "                 family=sm.genmod.families.family.NegativeBinomial(link=sm.genmod.families.links.log,\n",
    "                                                                   alpha=2.7))\n",
    "neg_bin_interact_results = neg_bin_interact.fit()\n",
    "y_pred_interact = neg_bin_interact_results.predict(poly.fit_transform(X_n_binom))\n",
    "neg_bin_interact_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_interact_pred = neg_bin_interact_results.predict(poly.fit_transform(X_n_binom))\n",
    "\n",
    "resid_plot(y_interact_pred, y_n_binom, 'Neg_binom + Interaction Terms')\n",
    "plt.savefig('/Users/ryanlambert/Desktop/neg_binom_interaction_resids.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_neg_binom_interact(y, X, alpha=2.7):\n",
    "    iterator = KFold(len(X), n_folds=5, shuffle=True)\n",
    "    scores = []\n",
    "    for train, test in iterator:\n",
    "        y_tr = y[train]\n",
    "        X_tr = X.values[train, :]\n",
    "        y_test = y[test]\n",
    "        X_test = X.values[test, :]\n",
    "        poly = PolynomialFeatures(2, interaction_only=True)\n",
    "        model = sm.GLM(y_tr,\n",
    "                    poly.fit_transform(X_tr),\n",
    "                    family=sm.genmod.families.family.NegativeBinomial(link=sm.genmod.families.links.log,\n",
    "                                                                       alpha=alpha))\n",
    "        model_results = model.fit()\n",
    "        y_pred_cross = model_results.predict(poly.fit_transform(X_test))\n",
    "        scores.append(mean_squared_error(y_test, y_pred_cross))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This looks better. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like I'm in the right expectation range.\n",
    "\n",
    "Still some variance in there I'm not capturing in my model.  \n",
    "\n",
    "This kind of makes sense since there is a 3-6 hour block of time wear use goes to zero.  Perhaps I use model stacking and use a separate model for these data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chi Sq Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linspace(2.6, 2.8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking\n",
    "More than one model to solve this system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over600 = data6[data6['count']>600]\n",
    "under600 = data6[data6['count']<600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over600.groupby(over600.index.month).mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "under600.groupby(under600.index.month).mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Submission with Cleaning \n",
    "\n",
    "name = 'neg_binom'\n",
    "X_test_data = get_transform_test_data(X_n_binom.columns)\n",
    "X_test_data[['spring', 'fall', 'winter', 'summer', 'heavy', 'light', 'clear', 'mist']] = X_test_data[['spring', 'fall', 'winter', 'summer', 'heavy', 'light', 'clear', 'mist']].astype(int)\n",
    "# X_test_data = sm.add_constant(X_test_data)\n",
    "predictions = neg_bin_results.predict(poly.fit_transform(X_test_data))\n",
    "kaggle_submission = pd.DataFrame(zip(test_data.index, predictions))\n",
    "kaggle_submission.columns = ['datetime', 'count']\n",
    "kaggle_submission = kaggle_submission.set_index('datetime')\n",
    "kaggle_submission.to_csv('data/{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transform_test_data(train_x_cols):\n",
    "    test_data = pd.read_csv('./data/test.csv')\n",
    "    test_data = clean_frame(test_data)\n",
    "    test_data = add_dummy_hours(test_data)\n",
    "    test_data = add_month_dummies(test_data)\n",
    "    test_data = test_data[train_x_cols]\n",
    "    return test_data\n",
    "\n",
    "def submissionize_sklearn(test_data, model, name):\n",
    "    predictions = model.predict(test_data)\n",
    "    kaggle_submission = pd.DataFrame(zip(test_data.index, predictions))\n",
    "    kaggle_submission.columns = ['datetime', 'count']\n",
    "    kaggle_submission = kaggle_submission.set_index('datetime')\n",
    "    kaggle_submission.to_csv('data/{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Include cross terms of time dummies with holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
